{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3453a470",
   "metadata": {},
   "source": [
    "1. Create notebook = done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ad57a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pydataset import data\n",
    "import env\n",
    "import os\n",
    "import acquire \n",
    "import prepare\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56519c84",
   "metadata": {},
   "source": [
    "**2. In the context of this problem, what is a false positive?**\n",
    "\n",
    "**In the context of this problem, what is a false negative?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cecf48",
   "metadata": {},
   "source": [
    "Dog is positive, Cat is negative\n",
    "\n",
    "FP = actual cat, predicted dog\n",
    "FN = actual dog, predicted cat\n",
    "\n",
    "Model is a crosstab of two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd6e5c",
   "metadata": {},
   "source": [
    "**3. An internal team wants to investigate the cause of the manufacturing defects. They tell you that they want to identify as many of the ducks that have a defect as possible. Which evaluation metric would be appropriate here? Which model would be the best fit for this use case?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387f67c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model1  model2     model3\n",
       "0  No Defect  No Defect  Defect  No Defect\n",
       "1  No Defect  No Defect  Defect     Defect\n",
       "2  No Defect  No Defect  Defect  No Defect\n",
       "3  No Defect     Defect  Defect     Defect\n",
       "4  No Defect  No Defect  Defect  No Defect"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal = pd.read_csv('c3.csv')\n",
    "abnormal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c795c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Defect    184\n",
       "Defect        16\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782b9ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual     model1  model2     model3   baseline\n",
       "0  No Defect  No Defect  Defect  No Defect  No Defect\n",
       "1  No Defect  No Defect  Defect     Defect  No Defect\n",
       "2  No Defect  No Defect  Defect  No Defect  No Defect\n",
       "3  No Defect     Defect  Defect     Defect  No Defect\n",
       "4  No Defect  No Defect  Defect  No Defect  No Defect"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal['baseline'] = 'No Defect'\n",
    "abnormal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03a87e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948a1adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of defects for entire batch\n",
    "percent_of_defects = (abnormal['actual']=='Defect').sum() / abnormal.shape[0]\n",
    "percent_of_defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8afdcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Accuracy\n",
    "baseline_acc = (abnormal['actual'] == abnormal['baseline']).mean()\n",
    "baseline_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4632485a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 1\n",
    "modelyek_acc = (abnormal['actual'] == abnormal['model1']).mean()\n",
    "modelyek_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51bb4552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 2\n",
    "modeldo_acc = (abnormal['actual'] == abnormal['model2']).mean()\n",
    "modeldo_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "080febff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.555"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy of model 3\n",
    "modelseh_acc = (abnormal['actual'] == abnormal['model3']).mean()\n",
    "modelseh_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338f0eca",
   "metadata": {},
   "source": [
    "**Precision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa0641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actual  model1     model2     model3   baseline\n",
       "3   No Defect  Defect     Defect     Defect  No Defect\n",
       "30     Defect  Defect  No Defect     Defect  No Defect\n",
       "62  No Defect  Defect  No Defect  No Defect  No Defect\n",
       "65     Defect  Defect     Defect     Defect  No Defect\n",
       "70     Defect  Defect     Defect     Defect  No Defect"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision  TP / TP+FP\n",
    "\n",
    "subset_p = abnormal[abnormal['model1']=='Defect']\n",
    "subset_p.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd39b375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision cont.\n",
    "\n",
    "model_p = (subset_p['model1'] == subset_p['actual']).mean()\n",
    "model_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671060f",
   "metadata": {},
   "source": [
    "**Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6efc8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual     model1     model2  model3   baseline\n",
       "13  Defect  No Defect     Defect  Defect  No Defect\n",
       "30  Defect     Defect  No Defect  Defect  No Defect\n",
       "65  Defect     Defect     Defect  Defect  No Defect\n",
       "70  Defect     Defect     Defect  Defect  No Defect\n",
       "74  Defect  No Defect  No Defect  Defect  No Defect"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall     TP / TP+FN\n",
    "subset_r = abnormal[abnormal['actual']=='Defect']\n",
    "subset_r.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed0b2db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall cont.\n",
    "\n",
    "model_recall = (subset_r['model1'] == subset_r['actual']).mean()\n",
    "model_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07cf85a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(subset_r['model2'] == subset_r['actual']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "21057197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(subset_r['model3'] == subset_r['actual']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034daf60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b> Recall Evaluation Metric<b>:\n",
    "<br> - Use this metric to find as many bad ducklings per model. This way even if there are false positives, there will be less bad ducklings missed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c854c",
   "metadata": {},
   "source": [
    "**3. Recently several stories in the local news have come out highlighting customers who received a rubber duck with a defect, and portraying C3 in a bad light. The PR team has decided to launch a program that gives customers with a defective duck a vacation to Hawaii. They need you to predict which ducks will have defects, but tell you the really don't want to accidentally give out a vacation package when the duck really doesn't have a defect. Which evaluation metric would be appropriate here? Which model would be the best fit for this use case?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676af6ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b> Precision Evaluation Metric<b>:\n",
    "<br> - Use this metric to predict the amount of good ducklings out there, therefore being able to predict the number vacations that will actually be given. Also, less false positives, which means less free vacations given out. Precision model 1 calculated to have an 0.80 accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2f34cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "paws = pd.read_csv('gives_you_paws.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec8f127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4\n",
       "0    cat    cat    dog    cat    dog\n",
       "1    dog    dog    cat    cat    dog\n",
       "2    dog    cat    cat    cat    dog\n",
       "3    dog    dog    dog    cat    dog\n",
       "4    cat    cat    cat    dog    dog"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9d29e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog    3254\n",
       "cat    1746\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws.actual.value_counts()\n",
    "# more dogs than cats. dogs is the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1f7f2fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6508\n",
      "0.8074\n",
      "0.6304\n",
      "0.5096\n",
      "0.7426\n"
     ]
    }
   ],
   "source": [
    "# Baseline accuracy\n",
    "paws['baseline'] = 'dog'\n",
    "print((paws.actual == paws.baseline).mean())\n",
    "print((paws.actual == paws.model1).mean())\n",
    "print((paws.actual == paws.model2).mean())\n",
    "print((paws.actual == paws.model3).mean())\n",
    "print((paws.actual == paws.model4).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d6c021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline\n",
       "1    dog    dog    cat    cat    dog      dog\n",
       "3    dog    dog    dog    cat    dog      dog\n",
       "5    dog    dog    dog    dog    dog      dog\n",
       "7    cat    dog    cat    cat    dog      dog\n",
       "8    dog    dog    cat    dog    dog      dog"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision accuracy TP / TP+FP\n",
    "# Precision subsets for the model \n",
    "subset1 = paws[paws['model1']=='dog']\n",
    "subset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54e5fca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8900238338440586"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean of the model that has been subsetted\n",
    "\n",
    "model = (subset1.actual == subset1.model1).mean()\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0227187e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803318992009834"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall accuracy TP / TP+FN\n",
    "# subsets the actual column to subset for the atual positive cases\n",
    "\n",
    "subset2 = paws[paws['actual'] == 'dog']\n",
    "\n",
    "model2 = (subset2.actual == subset2.model1).mean()\n",
    "model2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c08f9f8",
   "metadata": {},
   "source": [
    "**4a. In terms of accuracy, how do the various models compare to the baseline model? Are any of the models better than the baseline?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = .65\n",
    "precision = .89\n",
    "recall = .80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7802e3a",
   "metadata": {},
   "source": [
    "Precision has the highest accuracy with 89%. Baseline is at 65% and recall is at 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec79bb6",
   "metadata": {},
   "source": [
    "**4b. Suppose you are working on a team that solely deals with dog pictures. Which of these models would you recommend?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "25c5cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION\n",
      "\n",
      "\n",
      "MODEL 1\n",
      "0.8900238338440586\n",
      "------------------\n",
      "\n",
      "MODEL 2\n",
      "0.8931767337807607\n",
      "------------------\n",
      "\n",
      "MODEL 3\n",
      "0.6598883572567783\n",
      "------------------\n",
      "\n",
      "MODEL 4\n",
      "0.7312485304490948\n"
     ]
    }
   ],
   "source": [
    "# Precision for all models\n",
    "\n",
    "subset1 = paws[paws['model1']=='dog']\n",
    "subset2 = paws[paws['model2']=='dog']\n",
    "subset3 = paws[paws['model3']=='dog']\n",
    "subset4 = paws[paws['model4']=='dog']\n",
    "\n",
    "\n",
    "print('PRECISION')\n",
    "print('\\n')\n",
    "print('MODEL 1')\n",
    "print((subset1.actual == subset1.model1).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 2')\n",
    "print((subset2.actual == subset2.model2).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 3')\n",
    "print((subset3.actual == subset3.model3).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 4')\n",
    "print((subset4.actual == subset4.model4).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff7faa",
   "metadata": {},
   "source": [
    "I would recommend precision as it limits the amount of false positives, which means there would be less cats in the dog albums and there would be few actual dogs that are actually predicted as cats. Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd08c4",
   "metadata": {},
   "source": [
    "**4c. Suppose you are working on a team that solely deals with cat pictures. Which of these models would you recommend?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d7bc7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline_cats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual model1 model2 model3 model4 baseline baseline_cats\n",
       "0    cat    cat    dog    cat    dog      dog           cat\n",
       "1    dog    dog    cat    cat    dog      dog           cat\n",
       "2    dog    cat    cat    cat    dog      dog           cat\n",
       "3    dog    dog    dog    cat    dog      dog           cat\n",
       "4    cat    cat    cat    dog    dog      dog           cat"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline for cats\n",
    "paws['baseline_cats'] = 'cat'\n",
    "paws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75eb2a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3492"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy of baseline cats for model 2\n",
    "\n",
    "(paws.actual == paws.baseline_cats).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55bd6884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8074\n",
      "0.6304\n",
      "0.5096\n",
      "0.7426\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of each model \n",
    "print((paws.model1 == paws.actual).mean())\n",
    "print((paws.model2 == paws.actual).mean())\n",
    "print((paws.model3 == paws.actual).mean())\n",
    "print((paws.model4 == paws.actual).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "221d0c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "      <th>model4</th>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline_cats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual model1 model2 model3 model4 baseline baseline_cats\n",
       "0     cat    cat    dog    cat    dog      dog           cat\n",
       "4     cat    cat    cat    dog    dog      dog           cat\n",
       "6     cat    cat    cat    cat    dog      dog           cat\n",
       "7     cat    dog    cat    cat    dog      dog           cat\n",
       "11    cat    cat    dog    cat    cat      dog           cat"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset3= paws[paws['actual']=='cat']\n",
    "subset3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a2705ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION\n",
      "\n",
      "\n",
      "MODEL 1\n",
      "0.6897721764420747\n",
      "------------------\n",
      "\n",
      "MODEL 2\n",
      "0.4841220423412204\n",
      "------------------\n",
      "\n",
      "MODEL 3\n",
      "0.358346709470305\n",
      "------------------\n",
      "\n",
      "MODEL 4\n",
      "0.8072289156626506\n"
     ]
    }
   ],
   "source": [
    "subset4 = paws[paws['model1']=='cat']\n",
    "subset5 = paws[paws['model2']=='cat']\n",
    "subset6 = paws[paws['model3']=='cat']\n",
    "subset7 = paws[paws['model4']=='cat']\n",
    "\n",
    "\n",
    "print('PRECISION')\n",
    "print('\\n')\n",
    "print('MODEL 1')\n",
    "print((subset4.actual == subset4.model1).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 2')\n",
    "print((subset5.actual == subset5.model2).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 3')\n",
    "print((subset6.actual == subset6.model3).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 4')\n",
    "print((subset7.actual == subset7.model4).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85e7e96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECALL\n",
      "\n",
      "\n",
      "MODEL 1\n",
      "0.8150057273768614\n",
      "------------------\n",
      "\n",
      "MODEL 2\n",
      "0.8906071019473081\n",
      "------------------\n",
      "\n",
      "MODEL 3\n",
      "0.5114547537227949\n",
      "------------------\n",
      "\n",
      "MODEL 4\n",
      "0.34536082474226804\n"
     ]
    }
   ],
   "source": [
    "# Recall for all models TP/ TP+FN\n",
    "\n",
    "print('RECALL')\n",
    "print('\\n')\n",
    "print('MODEL 1')\n",
    "print((subset3.actual == subset3.model1).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 2')\n",
    "print((subset3.actual == subset3.model2).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 3')\n",
    "print((subset3.actual == subset3.model3).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 4')\n",
    "print((subset3.actual == subset3.model4).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904cf95",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b> Recall Evaluation Metric<b>:\n",
    "<br> - This has the highest accuracy and if they are solely dealing with cat pictures, then it is in their benefit to try to identify as many cats as possible. This would also increase false positives as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe2877",
   "metadata": {},
   "source": [
    "**5. Follow the links below to read the documentation about each function, then apply those functions to the data from the previous problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45534cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4037\n",
      "0.6304\n",
      "0.5096\n",
      "3713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(paws.actual, paws.model1, normalize=False))\n",
    "print(accuracy_score(paws.actual, paws.model2))\n",
    "print(accuracy_score(paws.actual, paws.model3))\n",
    "print(accuracy_score(paws.actual, paws.model4, normalize=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16820373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76da8c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6897721764420747\n",
      "0.4841220423412204\n",
      "0.358346709470305\n",
      "0.8072289156626506\n",
      "\n",
      "\n",
      "PRECISION\n",
      "\n",
      "\n",
      "MODEL 1\n",
      "0.6897721764420747\n",
      "------------------\n",
      "\n",
      "MODEL 2\n",
      "0.4841220423412204\n",
      "------------------\n",
      "\n",
      "MODEL 3\n",
      "0.358346709470305\n",
      "------------------\n",
      "\n",
      "MODEL 4\n",
      "0.8072289156626506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(precision_score(paws.actual, paws.model1, pos_label='cat'))\n",
    "print(precision_score(paws.actual, paws.model2, pos_label='cat'))\n",
    "print(precision_score(paws.actual, paws.model3, pos_label='cat'))\n",
    "print(precision_score(paws.actual, paws.model4, pos_label='cat'))\n",
    "\n",
    "print('\\n')\n",
    "print('PRECISION')\n",
    "print('\\n')\n",
    "print('MODEL 1')\n",
    "print((subset4.actual == subset4.model1).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 2')\n",
    "print((subset5.actual == subset5.model2).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 3')\n",
    "print((subset6.actual == subset6.model3).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 4')\n",
    "print((subset7.actual == subset7.model4).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "35f35248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8150057273768614\n",
      "0.8906071019473081\n",
      "0.5114547537227949\n",
      "0.34536082474226804\n",
      "\n",
      "\n",
      "RECALL\n",
      "\n",
      "\n",
      "MODEL 1\n",
      "0.8150057273768614\n",
      "------------------\n",
      "\n",
      "MODEL 2\n",
      "0.8906071019473081\n",
      "------------------\n",
      "\n",
      "MODEL 3\n",
      "0.5114547537227949\n",
      "------------------\n",
      "\n",
      "MODEL 4\n",
      "0.34536082474226804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(recall_score(paws.actual, paws.model1, pos_label='cat'))\n",
    "print(recall_score(paws.actual, paws.model2, pos_label='cat'))\n",
    "print(recall_score(paws.actual, paws.model3, pos_label='cat'))\n",
    "print(recall_score(paws.actual, paws.model4, pos_label='cat'))\n",
    "\n",
    "print('\\n')\n",
    "print('RECALL')\n",
    "print('\\n')\n",
    "print('MODEL 1')\n",
    "print((subset3.actual == subset3.model1).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 2')\n",
    "print((subset3.actual == subset3.model2).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 3')\n",
    "print((subset3.actual == subset3.model3).mean())\n",
    "print('------------------\\n')\n",
    "print('MODEL 4')\n",
    "print((subset3.actual == subset3.model4).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e73312dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n         cat       0.69      0.82      0.75      1746\\n         dog       0.89      0.80      0.84      3254\\n\\n    accuracy                           0.81      5000\\n   macro avg       0.79      0.81      0.80      5000\\nweighted avg       0.82      0.81      0.81      5000\\n'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report(paws.actual, paws.model1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "43dce294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dog</th>\n",
       "      <th>cat</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.890024</td>\n",
       "      <td>0.689772</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.789898</td>\n",
       "      <td>0.820096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.803319</td>\n",
       "      <td>0.815006</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.809162</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.844452</td>\n",
       "      <td>0.747178</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.795815</td>\n",
       "      <td>0.810484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>3254.000000</td>\n",
       "      <td>1746.000000</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dog          cat  accuracy    macro avg  weighted avg\n",
       "precision     0.890024     0.689772    0.8074     0.789898      0.820096\n",
       "recall        0.803319     0.815006    0.8074     0.809162      0.807400\n",
       "f1-score      0.844452     0.747178    0.8074     0.795815      0.810484\n",
       "support    3254.000000  1746.000000    0.8074  5000.000000   5000.000000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(paws.actual, paws.model1, labels=['dog','cat'], output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0aff4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
